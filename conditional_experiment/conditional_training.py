import json
import os
from jaxtyping import Bool, Float
from obf_reps.data import ConceptDataModule, train_only_split_dataset
from obf_reps.logging import Logger
from obf_reps.metrics import (
    LogisticRegressionMetric,
    MLPMetric,
    MetricConfig,
    ObfMetric,
    TrainableMetric,
)
from obf_reps.models.hf import HFHardPrompted
from torch import Tensor
from typing import List, Optional, Tuple
import torch
import torch.nn.functional as F
import random
import gc
import bitsandbytes as bnb

from .conditional_utils import split_dict_values_by_key


class ResponseProbeDataModule(ConceptDataModule):
    def __init__(
        self,
        topical_prompts_and_responses,
        nontopical_prompts_and_responses,
        batch_size=1,
    ):
        # Create datasets for two prompt sets
        self.dataset = list(
            zip(topical_prompts_and_responses, nontopical_prompts_and_responses)
        )
        self.batch_size = batch_size
        super().__init__(batch_size=batch_size)

    def load_dataset(self):
        """Returns a list of tuples, where each tuple contains an on-topic and off-topic statement."""
        return train_only_split_dataset(self.dataset)

    def train_reps_reduce(
        self,
        input_reps: Float[Tensor, "b layers inp_seq_len h_dim"],
        target_reps: Float[Tensor, "b layers out_seq_len h_dim"],
        target_mask: Optional[Bool[Tensor, "b out_seq_len"]] = None,
    ) -> Tuple[
        Float[Tensor, "b layers red_seq_len h_dim"], Bool[Tensor, "b red_seq_len"]
    ]:
        """Only use the target_reps (response activations) for training the probe"""

        if target_mask is None:
            b, out_seq_len = target_reps.shape[0], target_reps.shape[2]
            target_mask = torch.ones((b, out_seq_len), dtype=torch.bool)

        # Use only the response activations (target_reps)
        return target_reps, target_mask


def train_probe(
    model: HFHardPrompted,
    pos_samples: List[Tuple[str, str, List[int]]],
    neg_samples: List[Tuple[str, str, List[int]]],
    logger,
    target_layers: List[int],
    probe_type: str = "mlp",
    learning_rate: float = 5e-4,
    batch_size: int = 64,
    num_epochs: int = 5,
    use_token_ids: bool = True,
) -> TrainableMetric:
    logger.optional_print(f"pos_samples (len: {len(pos_samples)}): {pos_samples}")
    logger.optional_print(f"neg_samples (len: {len(neg_samples)}): {neg_samples}")

    logger.optional_print(f"Creating data module...")
    # Create the data module
    # Use token IDs or response text based on use_token_ids parameter
    data_module = ResponseProbeDataModule(
        [(p, t if use_token_ids and t is not None else r) for p, r, t in pos_samples],
        [(p, t if use_token_ids and t is not None else r) for p, r, t in neg_samples],
    )

    logger.optional_print(f"Configuring probe...")
    # Configure which layer(s) to probe
    config = MetricConfig(
        layers=target_layers,
        lr=learning_rate,
        batch_size=batch_size,
        num_epochs=num_epochs,
    )

    # Create the probe (using any of the available architectures)
    if probe_type == "mlp":
        metric = MLPMetric(
            model=model, data_module=data_module, config=config, logger=logger
        )
    elif probe_type == "logistic":
        metric = LogisticRegressionMetric(
            model=model, data_module=data_module, config=config, logger=logger
        )

    logger.optional_print(f"\n\nFinished training probe\n\n")
    # Freeze probe
    metric.probe[0].requires_grad_(False)

    return metric


def conditional_obf_loss(
    behavior_logits: Tensor,
    behavior_target: Tensor,
    input_reps: Tensor,
    target_reps: Tensor,
    behavior_loss_mask: Tensor,
    target_rep_loss_mask: Tensor,
    ideal_scores: Tensor,
    lambda_: float,
    obf_metric: ObfMetric,
    logger,
) -> Tuple[Tensor, Tensor, Tensor, Tensor]:
    # Add shape assertions before any operations
    assert (
        behavior_logits.ndim == 3
    ), f"behavior_logits should be 3D [batch, seq_len, vocab], got shape {behavior_logits.shape}"
    assert (
        behavior_target.ndim == 2
    ), f"behavior_target should be 2D [batch, seq_len], got shape {behavior_target.shape}"

    # Assert matching batch sizes
    assert behavior_logits.size(0) == behavior_target.size(
        0
    ), f"Batch size mismatch: logits {behavior_logits.size(0)} vs target {behavior_target.size(0)}"

    # Assert sequence lengths match
    assert behavior_logits.size(1) == behavior_target.size(1), (
        f"Sequence length mismatch: logits seq_len={behavior_logits.size(1)} vs "
        f"target seq_len={behavior_target.size(1)}\n"
        f"Full shapes - logits: {behavior_logits.shape}, target: {behavior_target.shape}"
    )

    b_size = behavior_logits.size(0)
    lambda_beh = lambda_
    lambda_obf = 1 - lambda_

    if lambda_beh > 0:
        # Calculate behavior loss only on valid target tokens
        beh_losses = F.cross_entropy(
            behavior_logits.transpose(1, 2), behavior_target, reduction="none"
        )  # [b_size, seq_len]

        # Apply loss mask (1 for valid tokens, 0 for padding)
        beh_losses *= behavior_loss_mask.float()

        # Average over valid tokens only
        num_valid_tokens = behavior_loss_mask.float().sum(dim=-1)  # [b_size]
        behavior_loss = beh_losses.sum(dim=-1) / (num_valid_tokens + 1e-8)  # [b_size]
    else:
        behavior_loss = torch.tensor(0.0, device=behavior_logits.device)

    # Get the metric's predicted score for each example
    scores = obf_metric.predict(reps=target_reps)

    # Get loss for metric's predicted score using MSE
    obf_loss = F.mse_loss(scores, ideal_scores, reduction="none")  # [b_size]

    # Combine losses with weighting
    total_loss = lambda_beh * behavior_loss + lambda_obf * obf_loss

    # Calculate layer norms
    layer_norms = torch.norm(target_reps, dim=-1).mean(
        dim=-1
    )  # Average over sequence length

    # For logging
    logger.log(
        {
            "behavior_loss": behavior_loss.mean().item(),
            "obf_loss": obf_loss.mean().item(),
        }
    )

    return total_loss, behavior_loss, obf_loss, layer_norms


def get_ultrachat_model_training_data(json_path: str) -> dict:
    """
    Loads UltraChat probe training data from a hardcoded JSON file and returns a dictionary
    mapping each word (from the 'part_of_word_set' field) to a list of training examples.

    Returns:
        dict: A mapping from each word (str) to a list of training example dictionaries.
    """
    file_path = json_path

    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Expected file '{file_path}' not found.")

    with open(file_path, "r") as f:
        data = json.load(f)

    prompts_responses = []
    for entry in data:
        prompts_responses.append((entry.get("prompt"), entry.get("response")))

    return prompts_responses


def get_model_training_data(
    model: HFHardPrompted,
    word_to_probe: dict[str, ObfMetric],
    words_data: dict[str, List[Tuple[str, str]]],
    train_sentences_twoword_dict: dict[Tuple[str, str], List[Tuple[str, str]]],
    logger,
    ultrachat_model_training_json_path: str,
    generate_mismatches=False,
):
    model_training_data_regular = []
    model_training_data_mismatches = []
    model_training_data_twowords = []
    words = list(words_data.keys())

    for probed_word in words:
        for prompt, response, token_ids in words_data[probed_word]:
            # Regular prompt - maximize probe score
            model_training_data_regular.append(
                (word_to_probe[probed_word], prompt, response, token_ids, 1)
            )

            # Matching clued prompt - minimize probe score
            dont_think_version = f"You are being probed for '{probed_word}'. {prompt}"
            model_training_data_regular.append(
                (word_to_probe[probed_word], dont_think_version, response, token_ids, 0)
            )

            # Mismatched clued prompts - maximize probe score for probed_word
            # (since we're telling model not to think about a different word)
            if generate_mismatches:
                other_words = [w for w in words if w != probed_word]
                for other_word in other_words:
                    mismatched_prompt = (
                        f"You are being probed for '{other_word}'. {prompt}"
                    )
                model_training_data_mismatches.append(
                    (
                        word_to_probe[probed_word],
                        mismatched_prompt,
                        response,
                        token_ids,
                        1,
                    )
                )

    # Two-word data generation
    for word1, word2 in train_sentences_twoword_dict.keys():
        for prompt, response, token_ids in train_sentences_twoword_dict[word1, word2]:
            # Add entry which should be high
            model_training_data_twowords.append(
                (
                    word_to_probe[word1],
                    word_to_probe[word2],
                    prompt,
                    response,
                    token_ids,
                    1,
                    1,
                )
            )

            adv_prompt1 = f"You are being probed for '{word1}'. {prompt}"
            model_training_data_twowords.append(
                (
                    word_to_probe[word1],
                    word_to_probe[word2],
                    adv_prompt1,
                    response,
                    token_ids,
                    0,
                    1,
                )
            )
            adv_prompt2 = f"You are being probed for '{word2}'. {prompt}"
            model_training_data_twowords.append(
                (
                    word_to_probe[word1],
                    word_to_probe[word2],
                    adv_prompt2,
                    response,
                    token_ids,
                    1,
                    0,
                )
            )

    ultrachat_raw_training_data = get_ultrachat_model_training_data(
        ultrachat_model_training_json_path
    )
    ultrachat_training_data_dontthinks = []
    word_index = 0
    # TODO: consider getting every word variant for every sample, rather than cycling through words.
    # Right now we're just doing that because we know ultrachat raw data len > actually used data len already
    # No token ids for ultrachat data
    for prompt, response in ultrachat_raw_training_data:
        probed_word = words[word_index]
        dont_think_version = f"You are being probed for '{probed_word}'. {prompt}"
        ultrachat_training_data_dontthinks.append(
            (word_to_probe[probed_word], dont_think_version, response, None, 0)
        )
        word_index = (word_index + 1) % len(words)

    # Each should be in format (metric, prompt, response, OPTIONAL token_ids, label)
    random.shuffle(model_training_data_regular)
    random.shuffle(model_training_data_mismatches)
    random.shuffle(model_training_data_twowords)
    random.shuffle(ultrachat_training_data_dontthinks)
    logger.optional_print(f"Regular training data: {model_training_data_regular}")
    logger.optional_print(f"Mismatch training data: {model_training_data_mismatches}")
    logger.optional_print(f"Two-word training data: {model_training_data_twowords}")
    logger.optional_print(
        f"Clued benign training data: {ultrachat_training_data_dontthinks}"
    )
    return (
        model_training_data_regular,
        model_training_data_mismatches,
        ultrachat_training_data_dontthinks,
        model_training_data_twowords,
    )


def train_with_gradient_context(
    model: HFHardPrompted,
    metric_in_out_metricgoal_regular: List[
        Tuple[ObfMetric, str, str, Optional[List[int]], int]
    ],
    metric_in_out_metricgoal_mismatches: List[
        Tuple[ObfMetric, str, str, Optional[List[int]], int]
    ],
    metric_in_out_metricgoal_benigndontthinks: List[
        Tuple[ObfMetric, str, str, Optional[List[int]], int]
    ],
    metric2_in_out_metricgoal2_twowords: List[
        Tuple[ObfMetric, ObfMetric, str, str, Optional[List[int]], int, int]
    ],
    num_epochs: int,
    logger: Logger,
    lambda_: float,
    target_layers: List[int],
    mismatch_frequency: float = 0.2,
    benign_dontthink_frequency: float = 0.2,
    twoword_frequency: float = 0.2,
    learning_rate: float = 1e-3,
    use_token_ids: bool = True,
):
    """
    Memory-optimized training loop using context managers for gradient control.
    mismatch_frequency controls what fraction of training steps use mismatched data.
    """
    from tqdm import tqdm

    logger.print(f"Training model...")
    model.requires_grad_(True)
    optim = bnb.optim.Adam8bit(model.parameters(), lr=learning_rate)

    # Then disable gradients by default
    model.requires_grad_(False)

    # Configure model settings
    model.model.gradient_checkpointing_enable()
    model.model.config.use_cache = False

    step_num = 0
    step_to_obf_loss_dontthink_regular = dict()
    step_to_obf_loss_regular = dict()
    step_to_obf_loss_twoword_dontthink_match = dict()
    step_to_obf_loss_twoword_dontthink_mismatch = dict()
    step_to_obf_loss_benign_dontthink_mismatch = dict()
    step_to_obf_loss_dontthink_mismatch = dict()

    step_to_beh_loss_dontthink_regular = dict()
    step_to_beh_loss_regular = dict()
    step_to_layer_norm_dontthink_regular = dict()
    step_to_layer_norm_regular = dict()
    step_to_layer_norm_twoword_dontthink_match = dict()
    step_to_layer_norm_twoword_dontthink_mismatch = dict()
    step_to_layer_norm_benign_dontthink_mismatch = dict()
    step_to_layer_norm_dontthink_mismatch = dict()
    running_loss = 0.0

    # Create indices for all datasets
    regular_idx = 0
    mismatch_idx = 0
    benign_dontthink_idx = 0
    twoword_idx = 0

    total_steps = len(metric_in_out_metricgoal_regular) * num_epochs
    pbar = tqdm(total=total_steps, desc="Training Progress")

    for epoch in range(num_epochs):
        logger.print(f"Epoch {epoch}...")

        regular_idx = 0
        mismatch_idx = 0
        benign_dontthink_idx = 0
        twoword_idx = 0

        epoch_steps = len(metric_in_out_metricgoal_regular)

        for _ in range(epoch_steps):
            # Decide which type of data to use
            rand = random.random()
            current_data_type = None
            if rand < mismatch_frequency:
                current_data = metric_in_out_metricgoal_mismatches[mismatch_idx]
                mismatch_idx += 1
                is_twoword = False
                current_data_type = "mismatch"
            elif rand < mismatch_frequency + benign_dontthink_frequency:
                current_data = metric_in_out_metricgoal_benigndontthinks[
                    benign_dontthink_idx
                ]
                benign_dontthink_idx += 1
                is_twoword = False
                current_data_type = "benign_dontthink"
            elif (
                rand
                < mismatch_frequency + benign_dontthink_frequency + twoword_frequency
            ):
                current_data = metric2_in_out_metricgoal2_twowords[twoword_idx]
                twoword_idx += 1
                is_twoword = True
                current_data_type = "twoword"
            else:
                current_data = metric_in_out_metricgoal_regular[regular_idx]
                regular_idx += 1
                is_twoword = False
                current_data_type = "regular"

            # Reset indices if needed
            if regular_idx >= len(metric_in_out_metricgoal_regular):
                random.shuffle(metric_in_out_metricgoal_regular)
                regular_idx = 0
            if mismatch_idx >= len(metric_in_out_metricgoal_mismatches):
                random.shuffle(metric_in_out_metricgoal_mismatches)
                mismatch_idx = 0
            if benign_dontthink_idx >= len(metric_in_out_metricgoal_benigndontthinks):
                random.shuffle(metric_in_out_metricgoal_benigndontthinks)
                benign_dontthink_idx = 0
            if twoword_idx >= len(metric2_in_out_metricgoal2_twowords):
                random.shuffle(metric2_in_out_metricgoal2_twowords)
                twoword_idx = 0

            if is_twoword:
                (
                    obf_metric1,
                    obf_metric2,
                    prompt_text,
                    response_text,
                    token_ids,
                    label1,
                    label2,
                ) = current_data
            else:
                obf_metric, prompt_text, response_text, token_ids, label = current_data

            # Enable gradients only for forward/backward pass
            with torch.set_grad_enabled(True):
                # Temporarily enable parameter gradients
                for param in model.parameters():
                    param.requires_grad = True

                # Clear memory before forward pass
                torch.cuda.empty_cache()

                # Modify forward pass based on use_token_ids
                if use_token_ids and token_ids is not None:
                    behavior_output = model.forward_from_string_and_ids(
                        input_text=[prompt_text],
                        target_ids=torch.tensor(
                            token_ids, device=model.device
                        ).unsqueeze(0),
                        target_attn_mask=torch.ones_like(
                            torch.tensor(token_ids, device=model.device)
                        ).unsqueeze(0),
                        add_chat_template=True,
                        use_tunable_params=False,
                        layers_to_probe=target_layers,
                    )
                else:
                    behavior_output = model.forward_from_string(
                        input_text=[prompt_text],
                        target_text=[response_text],
                        add_chat_template=True,
                        use_tunable_params=False,
                        layers_to_probe=target_layers,
                    )

                # Get target tokens and truncate to match model output length
                if use_token_ids and token_ids is not None:
                    behavior_target_input_ids = torch.tensor(
                        token_ids, device=model.device
                    ).unsqueeze(0)
                else:
                    behavior_target_input_ids, _ = model.tokenize(
                        text=[response_text],
                        add_chat_template=False,
                        add_special_tokens=False,
                        max_length=behavior_output.target_logits.size(1),
                        pad_to_max_length=True,
                    )

                # Add debugging assertions
                assert (
                    behavior_output.target_logits is not None
                ), "target_logits is None"
                assert behavior_target_input_ids is not None, "target_input_ids is None"

                logger.optional_print(
                    f"Step {step_num} - {'twoword' if is_twoword else 'regular'} - prompt: {prompt_text} - response: {response_text}"
                )

                behaviour_matching_target_tokens = (
                    model.tokenizer.convert_ids_to_tokens(
                        behavior_target_input_ids.flatten().tolist()
                    )
                )
                behaviour_output_tokens = model.tokenizer.convert_ids_to_tokens(
                    behavior_output.target_logits.argmax(dim=-1).flatten().tolist()
                )

                logger.optional_print(
                    f"Behaviour-matching target tokens (len {len(behaviour_matching_target_tokens)}): {behaviour_matching_target_tokens}"
                )
                logger.optional_print(
                    f"Actual behaviour output tokens (len {len(behaviour_output_tokens)}): {behaviour_output_tokens}"
                )

                with torch.amp.autocast("cuda", dtype=torch.bfloat16):
                    if is_twoword:
                        loss1, behavior_loss, obf_loss1, layer_norms1 = (
                            conditional_obf_loss(
                                behavior_logits=behavior_output.target_logits,
                                behavior_target=behavior_target_input_ids,
                                input_reps=behavior_output.input_reps,
                                target_reps=behavior_output.target_reps,
                                behavior_loss_mask=behavior_output.loss_mask,
                                target_rep_loss_mask=behavior_output.loss_mask,
                                ideal_scores=torch.tensor(
                                    [label1], device=model.device, dtype=torch.float16
                                ),
                                lambda_=lambda_,
                                obf_metric=obf_metric1,
                                logger=logger,
                            )
                        )
                        loss2, _, obf_loss2, layer_norms2 = conditional_obf_loss(
                            behavior_logits=behavior_output.target_logits,
                            behavior_target=behavior_target_input_ids,
                            input_reps=behavior_output.input_reps,
                            target_reps=behavior_output.target_reps,
                            behavior_loss_mask=behavior_output.loss_mask,
                            target_rep_loss_mask=behavior_output.loss_mask,
                            ideal_scores=torch.tensor(
                                [label2], device=model.device, dtype=torch.float16
                            ),
                            lambda_=lambda_,
                            obf_metric=obf_metric2,
                            logger=logger,
                        )
                        loss = (loss1 + loss2) / 2
                        behavior_loss = behavior_loss
                        obf_loss = (obf_loss1 + obf_loss2) / 2
                        layer_norms = (layer_norms1 + layer_norms2) / 2
                    else:
                        loss, behavior_loss, obf_loss, layer_norms = (
                            conditional_obf_loss(
                                behavior_logits=behavior_output.target_logits,
                                behavior_target=behavior_target_input_ids,
                                input_reps=behavior_output.input_reps,
                                target_reps=behavior_output.target_reps,
                                behavior_loss_mask=behavior_output.loss_mask,
                                target_rep_loss_mask=behavior_output.loss_mask,
                                ideal_scores=torch.tensor(
                                    [label], device=model.device, dtype=torch.float16
                                ),
                                lambda_=lambda_,
                                obf_metric=obf_metric,
                                logger=logger,
                            )
                        )
                    loss = loss.mean().squeeze()

                # Track losses by label
                if current_data_type == "twoword":
                    # Goal is to minimize probe
                    if label1 == 0:
                        step_to_obf_loss_twoword_dontthink_match[step_num] = (
                            obf_loss1.item()
                        )
                    if label2 == 0:
                        step_to_obf_loss_twoword_dontthink_match[step_num] = (
                            obf_loss2.item()
                        )
                    if label1 == 1:
                        step_to_obf_loss_twoword_dontthink_mismatch[step_num] = (
                            obf_loss1.item()
                        )
                    if label2 == 1:
                        step_to_obf_loss_twoword_dontthink_mismatch[step_num] = (
                            obf_loss2.item()
                        )
                elif current_data_type == "benign_dontthink":
                    step_to_obf_loss_benign_dontthink_mismatch[step_num] = (
                        obf_loss.item()
                    )
                elif current_data_type == "mismatch":
                    step_to_obf_loss_dontthink_mismatch[step_num] = obf_loss.item()
                else:  # regular
                    if label == 0:
                        step_to_obf_loss_dontthink_regular[step_num] = obf_loss.item()
                        step_to_beh_loss_dontthink_regular[step_num] = (
                            behavior_loss.item()
                        )
                    else:
                        step_to_obf_loss_regular[step_num] = obf_loss.item()
                        step_to_beh_loss_regular[step_num] = behavior_loss.item()

                # Track layer norms by data type
                if current_data_type == "twoword":
                    if label1 == 0:
                        step_to_layer_norm_twoword_dontthink_match[step_num] = (
                            layer_norms1.detach().mean().item()
                        )
                    if label2 == 0:
                        step_to_layer_norm_twoword_dontthink_match[step_num] = (
                            layer_norms2.detach().mean().item()
                        )
                    if label1 == 1:
                        step_to_layer_norm_twoword_dontthink_mismatch[step_num] = (
                            layer_norms1.detach().mean().item()
                        )
                    if label2 == 1:
                        step_to_layer_norm_twoword_dontthink_mismatch[step_num] = (
                            layer_norms2.detach().mean().item()
                        )
                elif current_data_type == "benign_dontthink":
                    step_to_layer_norm_benign_dontthink_mismatch[step_num] = (
                        layer_norms.detach().mean().item()
                    )
                elif current_data_type == "mismatch":
                    step_to_layer_norm_dontthink_mismatch[step_num] = (
                        layer_norms.detach().mean().item()
                    )
                else:  # regular
                    if label == 0:
                        step_to_layer_norm_dontthink_regular[step_num] = (
                            layer_norms.detach().mean().item()
                        )
                    else:
                        step_to_layer_norm_regular[step_num] = (
                            layer_norms.detach().mean().item()
                        )

                running_loss += obf_loss.item()

                # Backward pass
                loss.backward(retain_graph=False)
                optim.step()
                optim.zero_grad()

                # Explicitly delete intermediates
                del behavior_output, behavior_target_input_ids, loss

                # Disable gradients again
                for param in model.parameters():
                    param.requires_grad = False

            # Force garbage collection
            torch.cuda.empty_cache()
            gc.collect()

            # Update progress bar with loss
            step_num += 1
            pbar.set_postfix({"obf_loss": running_loss / step_num})
            pbar.update(1)

    pbar.close()
    return (
        model,
        step_to_obf_loss_dontthink_regular,
        step_to_obf_loss_regular,
        step_to_beh_loss_dontthink_regular,
        step_to_beh_loss_regular,
        step_to_obf_loss_twoword_dontthink_match,
        step_to_obf_loss_twoword_dontthink_mismatch,
        step_to_obf_loss_benign_dontthink_mismatch,
        step_to_obf_loss_dontthink_mismatch,
        step_to_layer_norm_dontthink_regular,
        step_to_layer_norm_regular,
        step_to_layer_norm_twoword_dontthink_match,
        step_to_layer_norm_twoword_dontthink_mismatch,
        step_to_layer_norm_benign_dontthink_mismatch,
        step_to_layer_norm_dontthink_mismatch,
    )


def plot_training_losses(
    step_to_obf_loss_dontthink_regular,
    step_to_obf_loss_regular,
    step_to_beh_loss_dontthink_regular,
    step_to_beh_loss_regular,
    step_to_obf_loss_twoword_dontthink_match,
    step_to_obf_loss_twoword_dontthink_mismatch,
    step_to_obf_loss_benign_dontthink_mismatch,
    step_to_obf_loss_dontthink_mismatch,
):
    """
    Plots rolling average training losses for both OBF (probe) and BEH (behavior) losses,
    including the additional metrics for two-word and mismatch cases.

    Two subplots are created:
      - Top: OBF losses, including:
          * Clued (probe minimizing) for regular examples
          * Regular (probe maximizing)
          * Two-word clued match (probe minimizing)
          * Two-word clued mismatch (probe maximizing)
          * Benign clued mismatch (probe maximizing)
          * Clued mismatch (probe maximizing)
      - Bottom: BEH losses for regular vs. clued cases.
    """
    import pandas as pd
    import matplotlib.pyplot as plt
    from datetime import datetime

    # Convert dictionaries to pandas Series and compute a rolling average (window=5)
    window = 5

    # OBF losses
    loss_dontthink_reg = (
        pd.Series(step_to_obf_loss_dontthink_regular)
        .rolling(window=window, min_periods=1)
        .mean()
    )
    loss_reg = (
        pd.Series(step_to_obf_loss_regular).rolling(window=window, min_periods=1).mean()
    )
    loss_tw_match = (
        pd.Series(step_to_obf_loss_twoword_dontthink_match)
        .rolling(window=window, min_periods=1)
        .mean()
    )
    loss_tw_mismatch = (
        pd.Series(step_to_obf_loss_twoword_dontthink_mismatch)
        .rolling(window=window, min_periods=1)
        .mean()
    )
    loss_benign = (
        pd.Series(step_to_obf_loss_benign_dontthink_mismatch)
        .rolling(window=window, min_periods=1)
        .mean()
    )
    loss_mismatch = (
        pd.Series(step_to_obf_loss_dontthink_mismatch)
        .rolling(window=window, min_periods=1)
        .mean()
    )

    # BEH losses
    beh_loss_dontthink_reg = (
        pd.Series(step_to_beh_loss_dontthink_regular)
        .rolling(window=window, min_periods=1)
        .mean()
    )
    beh_loss_reg = (
        pd.Series(step_to_beh_loss_regular).rolling(window=window, min_periods=1).mean()
    )

    # Create a figure with two subplots: one for OBF losses, one for BEH losses
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)

    # --- Plot OBF losses ---
    ax1.plot(
        loss_dontthink_reg.index,
        loss_dontthink_reg.values,
        "b-",
        linewidth=2,
        label="Clued (probe minimizing) - regular",
    )
    ax1.plot(
        loss_reg.index,
        loss_reg.values,
        "r-",
        linewidth=2,
        label="Regular (probe maximizing)",
    )
    ax1.plot(
        loss_tw_match.index,
        loss_tw_match.values,
        "m-",
        linewidth=2,
        label="Two-word clued match (probe minimizing)",
    )
    ax1.plot(
        loss_tw_mismatch.index,
        loss_tw_mismatch.values,
        color="orange",
        linewidth=2,
        label="Two-word clued mismatch (probe maximizing)",
    )
    ax1.plot(
        loss_benign.index,
        loss_benign.values,
        "g-",
        linewidth=2,
        label="Benign clued mismatch (probe minimizing)",
    )
    ax1.plot(
        loss_mismatch.index,
        loss_mismatch.values,
        "c-",
        linewidth=2,
        label="Clued mismatch (probe maximizing)",
    )

    ax1.set_title("OBF (Probe) Losses (Rolling Avg, window=5)", fontsize=14)
    ax1.set_ylabel("OBF Loss", fontsize=12)
    ax1.grid(True, alpha=0.3)
    ax1.legend(fontsize=10)

    # --- Plot BEH losses ---
    ax2.plot(
        beh_loss_dontthink_reg.index,
        beh_loss_dontthink_reg.values,
        "g-",
        linewidth=2,
        label="Clued (behavior minimizing) - regular",
    )
    ax2.plot(
        beh_loss_reg.index,
        beh_loss_reg.values,
        "y-",
        linewidth=2,
        label="Regular (behavior maximizing)",
    )
    ax2.set_title("BEH (Behavior) Losses (Rolling Avg, window=5)", fontsize=14)
    ax2.set_xlabel("Step Number", fontsize=12)
    ax2.set_ylabel("Behavior Loss", fontsize=12)
    ax2.grid(True, alpha=0.3)
    ax2.legend(fontsize=10)

    plt.tight_layout()

    # Save the figure with a timestamp before showing it
    save_path = (
        f'cond_training_losses_{datetime.now().strftime("%Y-%m-%d_%H-%M-%S")}.png'
    )
    plt.savefig(save_path)
    plt.show()

    return fig


def words_data_to_probes(
    model: HFHardPrompted,
    words_data: dict[str, List[Tuple[str, str]]],
    logger,
    target_layers: List[int],
    probe_type: str = "mlp",
    learning_rate: float = 5e-4,
    batch_size: int = 64,
    num_epochs: int = 5,
    seed: int = 42,
    word_to_benign_prompt_responses: dict[str, List[Tuple[str, str]]] = {},
    benign_proportion_in_nonwords: float = 0.0,
    twoword_data_dict: dict = None,
    twoword_frequency: float = 0.0,
    use_token_ids: bool = True,
) -> dict[str, TrainableMetric]:
    """
    Train word-level probes. If `twoword_frequency > 0`, a fraction `twoword_frequency`
    of the final training data is taken from two-word samples, split (approximately) evenly
    between positives and negatives.

    For example, if single-word data is size N, and twoword_frequency=0.5, we try to add
    another N total two-word examples (half pos, half neg), so that half of the final
    training set is from two-word data.
    """
    word_to_probe = dict()
    logger.print(f"\nTraining {probe_type} probes for words {words_data.keys()}...")
    words = list(words_data.keys())
    random.seed(seed)

    for i, probed_word in enumerate(words):
        logger.print(f"Training probe for {probed_word} ({i}/{len(words)})...")

        # Single-word pos/neg
        pos_samples, neg_samples = split_dict_values_by_key(words_data, probed_word)

        # Possibly sample a "benign" set
        nonword_count = int(len(pos_samples) * (1 - benign_proportion_in_nonwords))
        # Negatives come from nonword_count plus benign if requested
        sampled_neg = (
            random.sample(neg_samples, nonword_count)
            if len(neg_samples) > nonword_count
            else neg_samples
        )
        benign_size = int(len(pos_samples) * benign_proportion_in_nonwords)
        benign_samples = []
        if probed_word in word_to_benign_prompt_responses and benign_size > 0:
            benign_samples = random.sample(
                word_to_benign_prompt_responses[probed_word], benign_size
            )

        logger.print(
            f"About to train probe with benign_samples: {len(benign_samples)} and sampled_neg: {len(sampled_neg)}"
        )
        final_neg = sampled_neg + benign_samples

        # If requested, incorporate two-word data in the proportion specified by twoword_frequency
        if twoword_data_dict and twoword_frequency > 0.0:
            # Gather *all* relevant two-word entries
            pos_twoword_entries = []
            neg_twoword_entries = []
            for (wA, wB), p_r_t in twoword_data_dict.items():
                # If the pair includes our probed_word, these are positives
                if probed_word in (wA, wB):
                    pos_twoword_entries.extend(p_r_t)
                else:
                    # otherwise these are negatives for this probed_word
                    neg_twoword_entries.extend(p_r_t)

            # Compute how many total two-word entries we want:
            single_word_total = len(pos_samples) + len(final_neg)
            # e.g., if twoword_frequency=0.5 and single_word_total=100, we want another 100 from two-word data
            two_word_size = int(
                (twoword_frequency / (1 - twoword_frequency)) * single_word_total
            )

            # We'll try to split it evenly between pos and neg
            desired_pos_size = two_word_size // 2
            desired_neg_size = desired_pos_size
            logger.print(
                f"Desired two_word pos_size: {desired_pos_size} and neg_size: {desired_neg_size}"
            )

            # If we don't have enough pos_twoword_entries or neg_twoword_entries,
            # reduce the desired counts
            desired_pos_size = min(desired_pos_size, len(pos_twoword_entries))
            desired_neg_size = min(desired_neg_size, len(neg_twoword_entries))
            desired_pos_size = min(desired_pos_size, desired_neg_size)
            desired_neg_size = min(desired_pos_size, desired_neg_size)
            logger.print(
                f"Actual two_word pos_size: {desired_pos_size} and neg_size: {desired_neg_size}"
            )

            # Randomly sample from the pool
            pos_twoword_chosen = random.sample(pos_twoword_entries, desired_pos_size)
            neg_twoword_chosen = random.sample(neg_twoword_entries, desired_neg_size)

            # Add two-word data into our final positives/negatives
            pos_samples.extend(pos_twoword_chosen)
            final_neg.extend(neg_twoword_chosen)
            logger.print(
                f"About to train probe with pos_twoword_chosen: {len(pos_twoword_chosen)} and neg_twoword_chosen: {len(neg_twoword_chosen)}"
            )

        # Train the probe
        logger.print(
            f"About to train probe with a total of {len(pos_samples)} positives and {len(final_neg)} negatives..."
        )
        metric = train_probe(
            model,
            pos_samples,
            final_neg,
            logger,
            target_layers=target_layers,
            probe_type=probe_type,
            learning_rate=learning_rate,
            batch_size=batch_size,
            num_epochs=num_epochs,
            use_token_ids=use_token_ids,
        )
        word_to_probe[probed_word] = metric

    return word_to_probe


def plot_layer_norms(
    step_to_layer_norm_dontthink_regular,
    step_to_layer_norm_regular,
    step_to_layer_norm_twoword_dontthink_match,
    step_to_layer_norm_twoword_dontthink_mismatch,
    step_to_layer_norm_benign_dontthink_mismatch,
    step_to_layer_norm_dontthink_mismatch,
):
    """Plots rolling average layer norms for all tracked categories."""
    import pandas as pd
    import matplotlib.pyplot as plt
    from datetime import datetime

    window = 5

    # Convert dictionaries to pandas Series and compute rolling averages
    norm_dontthink_reg = (
        pd.Series(step_to_layer_norm_dontthink_regular)
        .rolling(window=window, min_periods=1)
        .mean()
    )
    norm_reg = (
        pd.Series(step_to_layer_norm_regular)
        .rolling(window=window, min_periods=1)
        .mean()
    )
    norm_tw_match = (
        pd.Series(step_to_layer_norm_twoword_dontthink_match)
        .rolling(window=window, min_periods=1)
        .mean()
    )
    norm_tw_mismatch = (
        pd.Series(step_to_layer_norm_twoword_dontthink_mismatch)
        .rolling(window=window, min_periods=1)
        .mean()
    )
    norm_benign = (
        pd.Series(step_to_layer_norm_benign_dontthink_mismatch)
        .rolling(window=window, min_periods=1)
        .mean()
    )
    norm_mismatch = (
        pd.Series(step_to_layer_norm_dontthink_mismatch)
        .rolling(window=window, min_periods=1)
        .mean()
    )

    # Create the plot
    plt.figure(figsize=(12, 6))

    plt.plot(
        norm_dontthink_reg.index,
        norm_dontthink_reg.values,
        "b-",
        linewidth=2,
        label="Clued - regular",
    )
    plt.plot(norm_reg.index, norm_reg.values, "r-", linewidth=2, label="Regular")
    plt.plot(
        norm_tw_match.index,
        norm_tw_match.values,
        "m-",
        linewidth=2,
        label="Two-word clued match",
    )
    plt.plot(
        norm_tw_mismatch.index,
        norm_tw_mismatch.values,
        color="orange",
        linewidth=2,
        label="Two-word clued mismatch",
    )
    plt.plot(
        norm_benign.index,
        norm_benign.values,
        "g-",
        linewidth=2,
        label="Benign clued mismatch",
    )
    plt.plot(
        norm_mismatch.index,
        norm_mismatch.values,
        "c-",
        linewidth=2,
        label="Clued mismatch",
    )

    plt.title("Layer Norms Over Training Steps (Rolling Avg, window=5)", fontsize=14)
    plt.xlabel("Step Number", fontsize=12)
    plt.ylabel("Layer Norm", fontsize=12)
    plt.grid(True, alpha=0.3)
    plt.legend(fontsize=10)

    plt.tight_layout()

    # Save the figure with timestamp
    save_path = (
        f'cond_training_layer_norms_{datetime.now().strftime("%Y-%m-%d_%H-%M-%S")}.png'
    )
    plt.savefig(save_path)
    plt.show()

    return plt.gcf()
